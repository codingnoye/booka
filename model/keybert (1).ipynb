{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keybert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install konlpy\n",
        "!pip install -U -q PyDrive\n",
        "!pip install pymysql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27qx2MBByotr",
        "outputId": "dbec1ed9-699e-4cb7-d0db-b7c9d77d4cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.19.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.2.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcHAWjMZx-M8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import pymysql"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')                      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkbgmBCH6C-S",
        "outputId": "aa92714b-5e88-48b9-d3be-8b1887327e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/gdrive/My Drive/keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX87tFHE6B7R",
        "outputId": "3339362e-0f12-4ea3-b000-fcfa3e8bf98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/keybert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  DEVICE=torch.device('cuda')\n",
        "else:\n",
        "  DEVICE=torch.device('cpu')"
      ],
      "metadata": {
        "id": "MTuM7BkYdihC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens').to(DEVICE)"
      ],
      "metadata": {
        "id": "pr272dTHeHUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = pymysql.connect(host='mm.noye.work', user='blueturtle', password='flyturtle!', db='booka', charset='utf8mb4')\n",
        "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
        "book_path =\"Select id,title,intro,`desc`,`desc_pub`,`desc_index` From backend_book\"\n",
        "curs.execute(book_path)\n",
        "mc=curs.fetchall()\n",
        "books=pd.DataFrame(mc)\n",
        "\n",
        "#book_path = 'booka_backend_book.csv'\n",
        "#req_cols=['id','title','intro','desc','desc_pub','desc_index'] \n",
        "#books = pd.read_csv(book_path,usecols=req_cols,escapechar='\\\\') \n",
        "books=books.dropna(how='all')\n",
        "books=books.fillna('') # nan 값 바꿔주기 \n",
        "books=books[books['title'].map(len)+books['desc_pub'].map(len)+books['intro'].map(len)+books['desc'].map(len)++books['desc_index'].map(len) > 100]\n",
        "\n",
        "\n",
        "books=books.reset_index()\n",
        "books"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "8Bb-6tBZ87uS",
        "outputId": "e15e88e7-8826-4640-b2a8-cadfae82c405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index      id             title  \\\n",
              "0          0       2              묵향 1   \n",
              "1          1       6           미쳐야 미친다   \n",
              "2          2       8              템테이션   \n",
              "3          3      14  나는 왜 나를 사랑하지 못할까   \n",
              "4          4      17           삼국지 인물전   \n",
              "...      ...     ...               ...   \n",
              "31382  32538  618440               이방인   \n",
              "31383  32539  618604        근원의 시간 속으로   \n",
              "31384  32540  618651       현대 타이베이의 탄생   \n",
              "31385  32541  618705            돈의 연금술   \n",
              "31386  32542  618706    미래가 온다, 스마트 시티   \n",
              "\n",
              "                                                   intro  \\\n",
              "0                                                          \n",
              "1      조선시대 지식인의 내면을 사로잡았던 열정과 광기를 탐색한 글. 남이 손가락질을 하든...   \n",
              "2      &lt;빅 픽처&gt;의 작가 더글라스 케네디의 장편소설. 할리우드의 영화계와 방송...   \n",
              "3      독일 최고의 심리상담가 롤프 메르클레의 신작. 독일 아마존 베스트셀러 《감정사용설명...   \n",
              "4      책 속에는 총 32명의 인물이 나온다. 유표=문재인, 원술=김한길, 조자룡=조국, ...   \n",
              "...                                                  ...   \n",
              "31382  최연소 노벨 문학상 수상자인 카뮈의 작품으로, 출간 당시 많은 이들에게 신선한 충격...   \n",
              "31383  그린란드 빙하에서 지구의 숨겨진 시간을 찾아가는 한 지질학자의 깊은 사색과 기록을 ...   \n",
              "31384  일본 제국주의 시대, 대만의 타이베이가 고유한 의미의 '장소'에서 현대 도시 '공간...   \n",
              "31385  미국에서 가장 신뢰받는 돈 관리 코치이자 금융 전문가인 데이브 램지가 ‘돈의 진실’...   \n",
              "31386  인류의 과학 기술과 미래에 관한 이야기이다. ’스마트 시티의 제1원칙, 인간을 행복...   \n",
              "\n",
              "                                                    desc  \\\n",
              "0      PC통신에서 폭발적인 인기를 끌며 연재되던 그 인기가 그대로 출판으로 반영된 <묵향...   \n",
              "1      조선시대 지식인의 내면을 사로잡았던 열정과 광기를 탐색한 글. 남이 손가락질을 하든...   \n",
              "2      &lt;빅 픽처&gt;의 작가 더글라스 케네디의 장편소설. 한 시나리오 작가의 성공...   \n",
              "3      독일 최고의 심리상담가 롤프 메르클레의 신작. 독일 아마존 베스트셀러 《감정사용설명...   \n",
              "4      한 눈에 파악하는 대한민국 정치 지도. 책 속에는 총 32명의 인물이 나온다. 유표...   \n",
              "...                                                  ...   \n",
              "31382                                                      \n",
              "31383                                                      \n",
              "31384                                                      \n",
              "31385                                                      \n",
              "31386                                                      \n",
              "\n",
              "                                                desc_pub  \\\n",
              "0                                                          \n",
              "1                                                          \n",
              "2      한 번의 성공이 반드시 ‘영원한 성공’으로 귀결되지는 않는다!  \\n-전 세계 30...   \n",
              "3      나는 왜 이렇게 자존감이 낮을까?\\n\\n예민하고 쉽게 상처를 받는가?\\n남의 눈치를...   \n",
              "4      1. &lt;삼국지 인물전&gt; 특징\\n\\n삼국지와 대한민국 인물이 만났다!\\n안...   \n",
              "...                                                  ...   \n",
              "31382                                                      \n",
              "31383                                                      \n",
              "31384                                                      \n",
              "31385                                                      \n",
              "31386                                                      \n",
              "\n",
              "                                              desc_index  \n",
              "0      서문 : 현경과 탈마운명의 시작특이한 인물 2044호아수혈교의 출현음모(陰謀)기연(...  \n",
              "1      1. 벽癖에 들린 사람들\\n미쳐야 미친다 | 벽(癖)에 들린 사람들\\n굶어 죽은 천...  \n",
              "2                              제1부 \\n\\n제2부 \\n\\n옮긴이의 말 \\n  \n",
              "3      들어가며 | 당신은 완벽하진 않지만 사랑받을 만한 사람\\n\\nPART 1 당신은 있...  \n",
              "4      머리말 _ 온 나라에 썩는 냄새가 진동하는 안녕하지 못한 시대 5\\n\\n‘유표’ 문...  \n",
              "...                                                  ...  \n",
              "31382                                                     \n",
              "31383                                                     \n",
              "31384                                                     \n",
              "31385                                                     \n",
              "31386                                                     \n",
              "\n",
              "[31387 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09484f7b-4466-49f7-b777-a5f76aade444\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>intro</th>\n",
              "      <th>desc</th>\n",
              "      <th>desc_pub</th>\n",
              "      <th>desc_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>묵향 1</td>\n",
              "      <td></td>\n",
              "      <td>PC통신에서 폭발적인 인기를 끌며 연재되던 그 인기가 그대로 출판으로 반영된 &lt;묵향...</td>\n",
              "      <td></td>\n",
              "      <td>서문 : 현경과 탈마운명의 시작특이한 인물 2044호아수혈교의 출현음모(陰謀)기연(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>미쳐야 미친다</td>\n",
              "      <td>조선시대 지식인의 내면을 사로잡았던 열정과 광기를 탐색한 글. 남이 손가락질을 하든...</td>\n",
              "      <td>조선시대 지식인의 내면을 사로잡았던 열정과 광기를 탐색한 글. 남이 손가락질을 하든...</td>\n",
              "      <td></td>\n",
              "      <td>1. 벽癖에 들린 사람들\\n미쳐야 미친다 | 벽(癖)에 들린 사람들\\n굶어 죽은 천...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>템테이션</td>\n",
              "      <td>&amp;lt;빅 픽처&amp;gt;의 작가 더글라스 케네디의 장편소설. 할리우드의 영화계와 방송...</td>\n",
              "      <td>&amp;lt;빅 픽처&amp;gt;의 작가 더글라스 케네디의 장편소설. 한 시나리오 작가의 성공...</td>\n",
              "      <td>한 번의 성공이 반드시 ‘영원한 성공’으로 귀결되지는 않는다!  \\n-전 세계 30...</td>\n",
              "      <td>제1부 \\n\\n제2부 \\n\\n옮긴이의 말 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>나는 왜 나를 사랑하지 못할까</td>\n",
              "      <td>독일 최고의 심리상담가 롤프 메르클레의 신작. 독일 아마존 베스트셀러 《감정사용설명...</td>\n",
              "      <td>독일 최고의 심리상담가 롤프 메르클레의 신작. 독일 아마존 베스트셀러 《감정사용설명...</td>\n",
              "      <td>나는 왜 이렇게 자존감이 낮을까?\\n\\n예민하고 쉽게 상처를 받는가?\\n남의 눈치를...</td>\n",
              "      <td>들어가며 | 당신은 완벽하진 않지만 사랑받을 만한 사람\\n\\nPART 1 당신은 있...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>삼국지 인물전</td>\n",
              "      <td>책 속에는 총 32명의 인물이 나온다. 유표=문재인, 원술=김한길, 조자룡=조국, ...</td>\n",
              "      <td>한 눈에 파악하는 대한민국 정치 지도. 책 속에는 총 32명의 인물이 나온다. 유표...</td>\n",
              "      <td>1. &amp;lt;삼국지 인물전&amp;gt; 특징\\n\\n삼국지와 대한민국 인물이 만났다!\\n안...</td>\n",
              "      <td>머리말 _ 온 나라에 썩는 냄새가 진동하는 안녕하지 못한 시대 5\\n\\n‘유표’ 문...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31382</th>\n",
              "      <td>32538</td>\n",
              "      <td>618440</td>\n",
              "      <td>이방인</td>\n",
              "      <td>최연소 노벨 문학상 수상자인 카뮈의 작품으로, 출간 당시 많은 이들에게 신선한 충격...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31383</th>\n",
              "      <td>32539</td>\n",
              "      <td>618604</td>\n",
              "      <td>근원의 시간 속으로</td>\n",
              "      <td>그린란드 빙하에서 지구의 숨겨진 시간을 찾아가는 한 지질학자의 깊은 사색과 기록을 ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31384</th>\n",
              "      <td>32540</td>\n",
              "      <td>618651</td>\n",
              "      <td>현대 타이베이의 탄생</td>\n",
              "      <td>일본 제국주의 시대, 대만의 타이베이가 고유한 의미의 '장소'에서 현대 도시 '공간...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31385</th>\n",
              "      <td>32541</td>\n",
              "      <td>618705</td>\n",
              "      <td>돈의 연금술</td>\n",
              "      <td>미국에서 가장 신뢰받는 돈 관리 코치이자 금융 전문가인 데이브 램지가 ‘돈의 진실’...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31386</th>\n",
              "      <td>32542</td>\n",
              "      <td>618706</td>\n",
              "      <td>미래가 온다, 스마트 시티</td>\n",
              "      <td>인류의 과학 기술과 미래에 관한 이야기이다. ’스마트 시티의 제1원칙, 인간을 행복...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31387 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09484f7b-4466-49f7-b777-a5f76aade444')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09484f7b-4466-49f7-b777-a5f76aade444 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09484f7b-4466-49f7-b777-a5f76aade444');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)"
      ],
      "metadata": {
        "id": "AHvsPsnUy0du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_extraction(doc,top_n):\n",
        "\n",
        "  tokenized_doc = okt.pos(doc)\n",
        "  tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if word[1] == 'Noun'])\n",
        "  n_gram_range = (1,1)\n",
        "\n",
        "  count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
        "  candidates = count.get_feature_names_out()\n",
        "\n",
        "  doc_embedding = model.encode([doc])\n",
        "  candidate_embeddings = model.encode(candidates)\n",
        "  \n",
        "  \n",
        "  doc_embedding=torch.from_numpy(doc_embedding)\n",
        "  candidate_embeddings=torch.from_numpy(candidate_embeddings)\n",
        "  \n",
        "  doc_embedding=doc_embedding.to(DEVICE)\n",
        "  candidate_embeddings=candidate_embeddings.to(DEVICE)\n",
        "  \n",
        "  distances = cos(doc_embedding, candidate_embeddings)\n",
        "  \n",
        "  keywords = [candidates[index] for index in distances.argsort()[-top_n:]]\n",
        "  \n",
        "  return keywords"
      ],
      "metadata": {
        "id": "CbIJnjvNDDol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_key=dict()"
      ],
      "metadata": {
        "id": "ZxBtXp3nHxZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  #키워드 추출\n",
        "for i in tqdm(range(len(books))):\n",
        "  doc=books['desc_index'][i]+books['title'][i]+books['intro'][i]+books['desc'][i]+books['desc_pub'][i]\n",
        "  if(len(re.sub('[^가-힣]', '', doc))>30):\n",
        "    keyword=keyword_extraction(doc,8)\n",
        "    book_key[books['id'][i]]=keyword\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "QrAtDPDAEGUE",
        "outputId": "aee92ddb-57c3-4faf-84a0-caef10fb7774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 48/31387 [00:15<2:47:51,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b368f0c829d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'desc_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'desc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'desc_pub'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^가-힣]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbook_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-c203031fe39f>\u001b[0m in \u001b[0;36mkeyword_extraction\u001b[0;34m(doc, top_n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkeyword_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtokenized_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtokenized_nouns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_doc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Noun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mn_gram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_v=list(book_key.values())"
      ],
      "metadata": {
        "id": "_-EAgS5NEBQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter # 상위 n개 키워드 출력\n",
        "key_extend=[]\n",
        "for i in range(len(key_v)):\n",
        "  key_extend.extend(key_v[i])\n",
        "count=Counter(key_extend)\n",
        "count_200=count.most_common(n=200)\n",
        "dict_count_200=dict((x,y)for x,y in count_200 )\n",
        "dict_count_200\n",
        "count_200"
      ],
      "metadata": {
        "id": "EdQuds-PEBWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc51bc41-dba1-43e0-f016-b67c67cd79c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('사랑', 3637),\n",
              " ('소설', 3619),\n",
              " ('작가', 2502),\n",
              " ('한국', 2382),\n",
              " ('장편소설', 1525),\n",
              " ('문학', 1264),\n",
              " ('행복', 1212),\n",
              " ('일본', 1184),\n",
              " ('베스트셀러', 1012),\n",
              " ('드라마', 971),\n",
              " ('가지', 894),\n",
              " ('대한민국', 888),\n",
              " ('독자', 885),\n",
              " ('소설가', 882),\n",
              " ('번역', 866),\n",
              " ('고통', 865),\n",
              " ('주인공', 784),\n",
              " ('연애', 779),\n",
              " ('국내', 753),\n",
              " ('조선', 729),\n",
              " ('매력', 698),\n",
              " ('가치', 686),\n",
              " ('문제', 671),\n",
              " ('이야기', 658),\n",
              " ('슬픔', 624),\n",
              " ('시인', 613),\n",
              " ('경제', 582),\n",
              " ('서울', 561),\n",
              " ('죽음', 541),\n",
              " ('독서', 539),\n",
              " ('유머', 524),\n",
              " ('애정', 518),\n",
              " ('즐거움', 512),\n",
              " ('기술', 511),\n",
              " ('기도', 486),\n",
              " ('평생', 485),\n",
              " ('학습', 484),\n",
              " ('절망', 480),\n",
              " ('욕망', 478),\n",
              " ('노하우', 474),\n",
              " ('대한', 467),\n",
              " ('데뷔', 464),\n",
              " ('결혼', 461),\n",
              " ('두려움', 460),\n",
              " ('연인', 451),\n",
              " ('활용', 450),\n",
              " ('문학상', 449),\n",
              " ('철학', 447),\n",
              " ('기쁨', 427),\n",
              " ('자존감', 408),\n",
              " ('로맨스', 405),\n",
              " ('부모', 402),\n",
              " ('독일', 397),\n",
              " ('개정판', 395),\n",
              " ('눈물', 392),\n",
              " ('한국인', 389),\n",
              " ('공부', 387),\n",
              " ('전략', 385),\n",
              " ('학교', 384),\n",
              " ('지혜', 377),\n",
              " ('추리소설', 375),\n",
              " ('살인', 372),\n",
              " ('그리움', 371),\n",
              " ('낭만', 366),\n",
              " ('열정', 355),\n",
              " ('외로움', 355),\n",
              " ('글쓰기', 349),\n",
              " ('가족', 349),\n",
              " ('전쟁', 346),\n",
              " ('세계문학', 344),\n",
              " ('후회', 342),\n",
              " ('미스터리', 339),\n",
              " ('먼저', 335),\n",
              " ('용서', 335),\n",
              " ('공포', 335),\n",
              " ('공감', 334),\n",
              " ('투자', 334),\n",
              " ('친구', 334),\n",
              " ('교육', 333),\n",
              " ('웃음', 331),\n",
              " ('갈등', 328),\n",
              " ('성공', 327),\n",
              " ('과학', 323),\n",
              " ('우정', 322),\n",
              " ('정의', 315),\n",
              " ('한국어', 315),\n",
              " ('재미', 307),\n",
              " ('연습', 305),\n",
              " ('교사', 301),\n",
              " ('부자', 281),\n",
              " ('만화', 277),\n",
              " ('노래', 276),\n",
              " ('고양이', 272),\n",
              " ('자본주의', 272),\n",
              " ('좌절', 271),\n",
              " ('비판', 268),\n",
              " ('여성', 266),\n",
              " ('고독', 266),\n",
              " ('시적', 263),\n",
              " ('비즈니스', 256),\n",
              " ('주년', 252),\n",
              " ('사업', 249),\n",
              " ('경영', 249),\n",
              " ('매혹', 248),\n",
              " ('연출', 248),\n",
              " ('창업', 245),\n",
              " ('아내', 245),\n",
              " ('배려', 244),\n",
              " ('유혹', 241),\n",
              " ('어려움', 240),\n",
              " ('도전', 239),\n",
              " ('도쿄', 238),\n",
              " ('존중', 238),\n",
              " ('음식', 237),\n",
              " ('치유', 235),\n",
              " ('남녀', 234),\n",
              " ('질투', 234),\n",
              " ('프랑스', 232),\n",
              " ('시집', 230),\n",
              " ('출판사', 227),\n",
              " ('비밀', 226),\n",
              " ('어머니', 222),\n",
              " ('동화', 222),\n",
              " ('논리', 221),\n",
              " ('수상작', 220),\n",
              " ('철학자', 218),\n",
              " ('실수', 217),\n",
              " ('비극', 216),\n",
              " ('한글', 215),\n",
              " ('혁신', 215),\n",
              " ('마법', 213),\n",
              " ('배움', 213),\n",
              " ('아픔', 213),\n",
              " ('배우', 212),\n",
              " ('세계대전', 211),\n",
              " ('한반도', 209),\n",
              " ('노력', 209),\n",
              " ('네이버', 208),\n",
              " ('그림책', 205),\n",
              " ('심리학', 204),\n",
              " ('갑자기', 200),\n",
              " ('역설', 200),\n",
              " ('관계', 200),\n",
              " ('언니', 199),\n",
              " ('소망', 198),\n",
              " ('분석', 198),\n",
              " ('일상', 197),\n",
              " ('악마', 196),\n",
              " ('도덕', 196),\n",
              " ('집착', 195),\n",
              " ('신뢰', 195),\n",
              " ('첫사랑', 195),\n",
              " ('괴물', 194),\n",
              " ('희곡', 192),\n",
              " ('대전', 192),\n",
              " ('자유', 190),\n",
              " ('천재', 189),\n",
              " ('보상', 189),\n",
              " ('희망', 188),\n",
              " ('감사', 187),\n",
              " ('부산', 186),\n",
              " ('서울대', 185),\n",
              " ('효율', 185),\n",
              " ('사회', 185),\n",
              " ('세계', 185),\n",
              " ('경쟁력', 184),\n",
              " ('상상력', 183),\n",
              " ('단편소설', 183),\n",
              " ('한국사', 183),\n",
              " ('직장인', 183),\n",
              " ('북한', 181),\n",
              " ('중국', 181),\n",
              " ('크리스마스', 180),\n",
              " ('문학사', 180),\n",
              " ('쓰기', 180),\n",
              " ('경제학', 179),\n",
              " ('감정', 179),\n",
              " ('분노', 177),\n",
              " ('진실', 176),\n",
              " ('미소', 176),\n",
              " ('기업', 175),\n",
              " ('투자자', 175),\n",
              " ('지식', 175),\n",
              " ('직장', 173),\n",
              " ('조선시대', 170),\n",
              " ('문학평론가', 170),\n",
              " ('저자', 169),\n",
              " ('평화', 169),\n",
              " ('학생', 169),\n",
              " ('응원', 168),\n",
              " ('용기', 167),\n",
              " ('경험', 167),\n",
              " ('영웅', 166),\n",
              " ('요리', 166),\n",
              " ('시리즈', 165),\n",
              " ('오해', 165),\n",
              " ('배신', 165),\n",
              " ('동안', 165),\n",
              " ('범죄', 165),\n",
              " ('출연', 164)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('book_key.pkl','wb') as f:\n",
        "  pickle.dump(book_key,f)\n",
        "with open('book_key.pkl','rb') as f:\n",
        "  test = pickle.load(f)"
      ],
      "metadata": {
        "id": "6x7nYQTjKFwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################"
      ],
      "metadata": {
        "id": "6vXB0J_xJ1ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PjrC-0iBkET3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(200) # 그래프\n",
        "word = dict_count_200.keys()\n",
        "values = dict_count_200.values()\n",
        "\n",
        "plt.figure(figsize=(40,8))\n",
        "\n",
        "plt.bar(x, values)\n",
        "plt.xticks(x, word)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AxpM8koPEBcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(val): #카테고리 별 id\n",
        "  matching_word=[]\n",
        "  for key, value in book_key.items():\n",
        "    for i in value:\n",
        "      if val == i:\n",
        "        matching_word.append(key)\n",
        "  return matching_word\n",
        "\n",
        "result=get_key(count_200[0][0]) \n",
        "result"
      ],
      "metadata": {
        "id": "1oxxhPq7muZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################################"
      ],
      "metadata": {
        "id": "NFQXYJzkC678"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}